{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad53e0-61c9-4a69-9b34-388a7c8f78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pyzome as pzm\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import ticker as mticker\n",
    "\n",
    "#%matplotlib inline # uncomment if you want plots in the notebook to appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307a6ad-4aa6-47b4-bba5-927b8ec94cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import font_manager\n",
    "# font_manager.findSystemFonts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b0dab-6c35-43a4-98c9-c1f33b08ab8f",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Define general globals\n",
    "These will be used throughout the rest of the notebook, where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb239a-e239-42bd-ad71-2d8509bc4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are we reading data from?\n",
    "DATA_DIR = pathlib.Path(\"/gws/nopw/j04/snapsi/processed\")\n",
    "\n",
    "# Where are we saving plots to?\n",
    "PLOT_DIR = pathlib.Path(\"./plots/atlas\")\n",
    "\n",
    "# Overwrite old plot files? If false, this notebook will\n",
    "# skip any files that have already been made. If true, \n",
    "# it will overwrite (remake) them.\n",
    "CLOBBER = False\n",
    "\n",
    "# This will be used to guarantee the order of panels in plots. \n",
    "# If you prefer a different order, change the numeric values \n",
    "# accordingly (lower val = higher panel in the plot). \n",
    "PANEL_ORDER_PRECEDENCE = {\n",
    "    \"free\": 0,\n",
    "    \"nudged\": 1,\n",
    "    \"control\": 2,\n",
    "    \"nudged-full\": 3,\n",
    "    \"control-full\": 4,\n",
    "}\n",
    "\n",
    "# For labeling the modeling centres with their respective models\n",
    "CENTRE_TRANSLATOR = {\n",
    "    \"CNRM-CM61\": \"Meteo-France\",\n",
    "    \"GEM-NEMO\": \"ECCC\",\n",
    "    \"GLOBO\": \"CNR-ISAC\",\n",
    "    \"GRIMs\": \"SNU\",\n",
    "    \"GloSea6\": \"UKMO\",\n",
    "    \"GloSea6-GC32\": \"KMA\",\n",
    "}\n",
    "\n",
    "# for diagnostics that should only be plotted\n",
    "# for the relevant winter hemisphere\n",
    "HEMI_TRANSLATOR = {\n",
    "    \"s20180125\": 1,\n",
    "    \"s20180208\": 1,\n",
    "    \"s20181213\": 1,\n",
    "    \"s20190108\": 1,\n",
    "    \"s20190829\": -1,\n",
    "    \"s20191001\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37a0f0b-89b1-45bf-9355-66d27dc9c1c8",
   "metadata": {},
   "source": [
    "## Define plot globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25eee5c-9b50-4d91-8c07-06f5a3d224a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XMAJOR_LOCATOR = mdates.DayLocator([1,8,15,22])\n",
    "XMINOR_LOCATOR = mdates.DayLocator()\n",
    "XTICK_FORMATTER = mdates.DateFormatter(\"%y%m%d\")\n",
    "\n",
    "# use consistent colors for the different experiments\n",
    "# free is ~blue, nudged is ~orange, control is ~green,\n",
    "# nudged-full is ~light-orange, and control-full is \n",
    "# ~light-green (based on tab20 colors)\n",
    "EXPERIMENT_COLORS = {\n",
    "    \"free\": \"#004580\",\n",
    "    \"nudged\": \"#D04A00\",\n",
    "    \"nudged-full\": \"#D18847\",\n",
    "    \"control\": \"#057004\",\n",
    "    \"control-full\": \"#68B258\",\n",
    "}\n",
    "\n",
    "RC_PARAMS = {\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": \"Ubuntu\", # not many fonts available on the jasmin notebook system!\n",
    "    \"font.size\": 12,\n",
    "    \"xtick.major.size\": 7,\n",
    "    \"xtick.minor.size\": 4,\n",
    "    \"xtick.minor.visible\": True,\n",
    "    \"ytick.major.size\": 7,\n",
    "    \"ytick.minor.size\": 4,\n",
    "    \"ytick.minor.visible\": True,\n",
    "}\n",
    "for key,val in RC_PARAMS.items():\n",
    "    mpl.rcParams[key] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d1634-ecb3-4f9b-b385-197fa71f4e76",
   "metadata": {},
   "source": [
    "## Define the plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fece9-5f2e-45c9-93b6-1fce82d76827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plume_plots(\n",
    "    das: list[xr.DataArray], \n",
    "    obs: xr.DataArray, \n",
    "    titles: list[str], \n",
    "    suptitle: str, \n",
    "    ylabel: str=\"\", \n",
    "    ylim: tuple[float,float]=None,\n",
    "    colors: list[str]=None,\n",
    "):\n",
    "    \"\"\" Function for making quick & dirty plume plots of the SNAPSI data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    das : list of `xarray.DataArray`s\n",
    "        The data to plot in each panel. Each DataArray goes to one panel.\n",
    "        It's expected that every DataArray has the same time axis.\n",
    "    obs : `xarray.DataArray`\n",
    "        The observational data to overplot on top, in each panel.\n",
    "        It's expected that this data has exactly the same times\n",
    "        as all the arrays in das\n",
    "    titles : list of str\n",
    "        The titles for each panel. Should have as many titles as\n",
    "        the `DataArray`s in das\n",
    "    suptitle : str\n",
    "        The overall suptitle of the plot\n",
    "    ylabel : str, optional\n",
    "        The label for the y-axis. Defaults to an empty string\n",
    "    ylim : tuple of two floats\n",
    "        The ylim that should be applied to each panel. Defaults\n",
    "        to None, which mean the limits are auto-determined, but \n",
    "        consistent across the panels.\n",
    "    colors: list of strings\n",
    "        The hex-string of the colors to plot for each `DataArray` in das.\n",
    "        If provided, should have as many colors as the `DataArray`s in das.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig : \n",
    "        The matplotlib figure instance with the data plotted\n",
    "    \"\"\"\n",
    "    num_panels = len(das)\n",
    "    if len(titles) != num_panels:\n",
    "        raise ValueError(\"Number of titles should equal number of provided DataArrays\")\n",
    "\n",
    "    if not isinstance(colors, list) and len(colors) != num_panels:\n",
    "        raise ValueError(\"Number of colors should equal number of provided DataArrays\")\n",
    "    elif colors is None:\n",
    "        colors = [\"red\"]*num_panels\n",
    "\n",
    "    # Set up the figure \n",
    "    fig_width = 8\n",
    "    fig_height = 3.5*num_panels\n",
    "    fig_size = (fig_width, fig_height)\n",
    "    fig, axs = plt.subplots(nrows=num_panels, ncols=1, figsize=fig_size)\n",
    "\n",
    "    # loop over the DataArrays\n",
    "    lo_ylims, hi_ylims = [], []\n",
    "    for i,da in enumerate(das):\n",
    "        c = colors[i]\n",
    "        da.plot.line(ax=axs[i], hue=\"member_id\", alpha=0.25, linewidth=0.5, add_legend=False, color=c)\n",
    "        da.mean(\"member_id\").plot.line(ax=axs[i], linewidth=2.0, label=\"model\", color=c)\n",
    "        obs.plot.line(ax=axs[i], color=\"black\", linewidth=2.0, label=\"ERA5\")\n",
    "        axs[i].minorticks_on()\n",
    "\n",
    "        # keep track of the y-limits in case we need them later\n",
    "        # to set consistent ylims\n",
    "        ylo,yhi = axs[i].get_ylim()\n",
    "        lo_ylims.append(ylo)\n",
    "        hi_ylims.append(yhi)\n",
    "\n",
    "    # are we setting ylims ourselves?\n",
    "    if ylim is None:\n",
    "        ylim = (min(lo_ylims), max(hi_ylims))\n",
    "\n",
    "    # apply axis styling. we do this separate from the loop above\n",
    "    # in case we need to use information from the data plotted in\n",
    "    # all of the panels (such as the ylims)\n",
    "    for i,ax in enumerate(axs):\n",
    "        # x-axis\n",
    "        xlabel = \"Date [YYMMDD]\" if i == num_panels-1 else \"\"\n",
    "        ax.set_xlim(obs.time[0], obs.time[-1])\n",
    "        ax.xaxis.set_major_locator(XMAJOR_LOCATOR)\n",
    "        ax.xaxis.set_major_formatter(XTICK_FORMATTER)\n",
    "        ax.xaxis.set_minor_locator(XMINOR_LOCATOR)\n",
    "        ax.set_xlabel(xlabel, fontsize=14)\n",
    "        ax.tick_params(axis=\"x\", rotation=0)\n",
    "        xticklabels = ax.get_xticklabels()\n",
    "        for xtl in xticklabels:\n",
    "            xtl.set_ha(\"center\")\n",
    "\n",
    "        # y-axis\n",
    "        ax.set_ylabel(ylabel, fontsize=14)\n",
    "        ax.set_ylim(ylim)\n",
    "        ax.yaxis.set_ticks_position(\"both\")\n",
    "        if ylim[0] < 0 < ylim[1]:\n",
    "            axs[i].axhline(0, color=\"black\", linewidth=0.5, linestyle=\"-\")\n",
    "\n",
    "        # add a legend on first panel\n",
    "        if (i == 0):\n",
    "            ax.legend()\n",
    "        ax.set_title(titles[i], fontsize=16)\n",
    "\n",
    "    # Place the suptitle nicely, with respect to top axis\n",
    "    dy = 0.8925 # offset from top ax, to top of suptitle, in inches\n",
    "    plt.subplots_adjust(bottom=0.05, hspace=0.22)\n",
    "    l, b, w, h = axs[0].get_position().bounds\n",
    "    plt.suptitle(suptitle, fontsize=20, fontweight=\"semibold\", y=b+h+(dy/fig_height))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e547a7fc-ef86-4ef0-b5c7-47746258c36b",
   "metadata": {},
   "source": [
    "## Define the \"Atlas\" functions\n",
    "The idea of these functions is that they will take a zonal mean dataset read in by xarray,\n",
    "and return DataArrays for plume plots. You can define more, but the idea is that they should\n",
    "pull out a DataArray from a Dataset, and transform it so that it has only (at most)\n",
    "dimensions for `(member_id, time, level)`. If `level` is kept, the transformed data needs\n",
    "to be limited to a single level before sending it to the above plotting function, which \n",
    "expects only `(member_id, time)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4b8eb-1c3a-4430-b382-96e75343ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vt4575(ds: xr.Dataset, hemi: int, k: int):\n",
    "    \"\"\" 45-75 lat avg of eddy heat flux \"\"\"\n",
    "    if k == 0:\n",
    "        vt = ds['vT']\n",
    "    elif 0 < k < 4:\n",
    "        vt = ds['vT_k'].sel(wavenum_lon = k)\n",
    "    else:\n",
    "        raise ValueError(\"can only take wavenums from 1-3\")\n",
    "\n",
    "    if hemi == 1:\n",
    "        lats = (45, 75)\n",
    "    elif hemi == -1:\n",
    "        lats = (-75, -45)\n",
    "    else:\n",
    "        raise ValueError(\"hemi can only be 1 (NH) or -1 (SH)\")\n",
    "\n",
    "    return pzm.meridional_mean(vt, *lats).resample(time=\"1D\").mean(\"time\")\n",
    "\n",
    "\n",
    "def vt4575tot(ds: xr.Dataset, hemi: int):\n",
    "    return vt4575(ds, hemi, 0)\n",
    "    \n",
    "\n",
    "def t6090(ds: xr.Dataset, hemi: int):\n",
    "    \"\"\" 60-90 lat avg of temperature \"\"\"\n",
    "    if hemi == 1:\n",
    "        lats = (60, 90)\n",
    "    elif hemi == -1:\n",
    "        lats = (-90, 60)\n",
    "    else:\n",
    "        raise ValueError(\"hemi can only be 1 (NH) or -1 (SH)\")\n",
    "\n",
    "    return pzm.meridional_mean(ds[\"T\"], *lats).resample(time=\"1D\").mean(\"time\")\n",
    "\n",
    "\n",
    "def u60(ds: xr.Dataset, hemi: int):\n",
    "    \"\"\" zonal mean u at 60 degrees \"\"\"\n",
    "    if hemi == 1:\n",
    "        lat = 60\n",
    "    elif hemi == -1:\n",
    "        lat = -60\n",
    "    else:\n",
    "        raise ValueError(\"hemi can only be 1 (NH) or -1 (SH)\")\n",
    "        \n",
    "    return ds[\"u\"].interp(lat=lat).resample(time=\"1D\").mean(\"time\")\n",
    "\n",
    "\n",
    "def zamp60(ds: xr.Dataset, hemi: int, k: int):\n",
    "    \"\"\" amplitude of geohgt waves at 60 degrees \"\"\"\n",
    "    if hemi == 1:\n",
    "        lat = 60\n",
    "    elif hemi == -1:\n",
    "        lat = -60\n",
    "    else:\n",
    "        raise ValueError(\"hemi can only be 1 (NH) or -1 (SH)\")\n",
    "\n",
    "    if not 0 < k < 4:\n",
    "        raise ValueError(\"can only take wavenums from 1-3\")\n",
    "    \n",
    "    z_ks = (ds[\"Z_k_real\"] + 1j*ds[\"Z_k_imag\"]).sel(wavenum_lon=k)\n",
    "    \n",
    "    return (2*np.absolute(z_ks.interp(lat=lat))/ds.nlons).resample(time=\"1D\").mean(\"time\")\n",
    "\n",
    "\n",
    "def uqbo(ds: xr.Dataset, *args):\n",
    "    \"\"\" zonal winds averaged from -5 to 5 for QBO \"\"\"\n",
    "    return pzm.meridional_mean(ds[\"u\"], -5, 5).resample(time=\"1D\").mean(\"time\")\n",
    "\n",
    "\n",
    "def tqbo(ds: xr.Dataset, *args):\n",
    "    \"\"\" temperatures averaged from -5 to 5 for QBO \"\"\"\n",
    "    return pzm.meridional_mean(ds[\"T\"], -5, 5).resample(time=\"1D\").mean(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83b8aa-cab5-46bd-a009-d1d7be74071a",
   "metadata": {},
   "source": [
    "## Define the job parameters\n",
    "Top level of nested dictionary is the \"batch\" - the dictionary underneath it specifies\n",
    "which of the above functions should be called for each of the specified \n",
    "pressure levels / zonal wavenumbers, as well as strings that go into the eventual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167ec5b-0188-42b6-98d4-89d2a391c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_jobs = {\n",
    "    \"U60\": {\n",
    "        \"callback\": u60,\n",
    "        \"levels\": (10, 100),\n",
    "        \"suptitle\": \"{lev} hPa, 60°{hemi} Zonal Mean U\\n{centre} {model} {init}\",\n",
    "        \"ylabel\": \"Zonal Wind [m/s]\",\n",
    "    },\n",
    "    \"T6090\": {\n",
    "        \"callback\": t6090,\n",
    "        \"levels\": (10, 100),\n",
    "        \"suptitle\": \"{lev} hPa, 60-90°{hemi} Polar Cap T\\n{centre} {model} {init}\",\n",
    "        \"ylabel\": \"Temperature [K]\",\n",
    "    },\n",
    "    \"vT4575\": {\n",
    "        \"callback\": vt4575tot,\n",
    "        \"levels\": (50, 100, 300),\n",
    "        \"suptitle\": \"{lev} hPa, 45-75°{hemi} v'T'\\n{centre} {model} {init}\",\n",
    "        \"ylabel\": \"Eddy Heat Flux [K m/s]\",\n",
    "    },\n",
    "    \"UQBO\": {\n",
    "        \"callback\": uqbo,\n",
    "        \"levels\": (10, 30, 50),\n",
    "        \"suptitle\": \"{lev} hPa, 5°S-5°N QBO U\\n{centre} {model} {init}\",\n",
    "        \"ylabel\": \"Zonal Wind [m/s]\"\n",
    "    },\n",
    "    \"TQBO\": {\n",
    "        \"callback\": tqbo,\n",
    "        \"levels\": (50, 70, 100),\n",
    "        \"suptitle\": \"{lev} hPa, 5°S-5°N QBO T\\n{centre} {model} {init}\",\n",
    "        \"ylabel\": \"Temperature [K]\"\n",
    "    },\n",
    "}\n",
    "\n",
    "wavenum_jobs = {\n",
    "    \"Z60-amp-k\": {\n",
    "        \"callback\": zamp60,\n",
    "        \"levels\": (10, 100, 300),\n",
    "        \"wavenums\": (1, 2, 3),\n",
    "        \"suptitle\": \"{lev} hPa, 60°{hemi} Wave-{k} Amplitude\\n{centre} {model} {init}\",\n",
    "        \"ylabel\": \"Amplitude [m]\"\n",
    "    },\n",
    "    \"vT4575-k\": {\n",
    "        \"callback\": vt4575,\n",
    "        \"levels\": (50, 100, 300),\n",
    "        \"wavenums\": (1, 2, 3),\n",
    "        \"suptitle\": \"{lev} hPa, 45-75°{hemi} Wave-{k} v'T'\\n{centre} {model} {init}\",\n",
    "        \"ylabel\": \"Eddy Heat Flux [K m/s]\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c473d-77e8-4946-b7e6-8262a41c557a",
   "metadata": {},
   "source": [
    "# Begin the work\n",
    "## Get zonal mean files for obs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5aa2b3-a0f0-45a2-b356-97ea6436f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of zonal mean dataset files\n",
    "zmd_files = sorted(list(DATA_DIR.glob(\"**/*zonalmeans.nc\")))\n",
    "\n",
    "# We don't want the reanalysis files in the mix of the experimental data,\n",
    "# so separate these with list-comprehension filters\n",
    "era5_files = [fi for fi in zmd_files if \"ERA5\" in str(fi)]\n",
    "zmd_files = [fi for fi in zmd_files if \"ERA5\" not in str(fi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faccccb2-f39c-4ab8-8f01-8d926910dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make \"atlas\" figures, we want to group the zonal mean files by\n",
    "# the combination of the model and init date\n",
    "keygen = lambda fi: (fi.parts[6], fi.parts[8])\n",
    "grouped = {key: list(group) for key,group in itertools.groupby(sorted(zmd_files, key=keygen), keygen)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed8809-072d-416a-9344-cf6e00a18a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If you want to see what grouped now contains, try uncommenting/running\n",
    "\n",
    "# for key,group in grouped.items():\n",
    "#    print(f\"{key} -> {group}\")\n",
    "\n",
    "# Essentially, we get (model, init) -> list of files having the same model & init.\n",
    "# The key is the tuple, and the group is a generator (if you don't know what these\n",
    "# mean in the context of python, don't worry about it). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd1b00-0ace-439c-a7ff-f283d2f7a9c6",
   "metadata": {},
   "source": [
    "## Read in the reanalysis data\n",
    "This will be used across all of the atlas plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74823a-b210-4bda-ac32-3e866242cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rean_data = xr.open_mfdataset(era5_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37891b09-2d16-4a04-8a9c-026ab1750b5c",
   "metadata": {},
   "source": [
    "## Make the plots\n",
    "Below we loop over the different `(model, init)` combinations, then the regular job batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29392b55-f80f-445c-a23c-9cba3c040c0a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (model, init),group in grouped.items():\n",
    "    centre = CENTRE_TRANSLATOR[model]\n",
    "    hemi = HEMI_TRANSLATOR[init]\n",
    "    hs = \"N\" if hemi == 1 else \"S\"\n",
    "\n",
    "    # sort the group of files in panel order \n",
    "    files_to_read = sorted(list(group), key = lambda fi: PANEL_ORDER_PRECEDENCE[fi.parts[7]]) \n",
    "    experiments = [fi.parts[7] for fi in files_to_read]\n",
    "    colors = [EXPERIMENT_COLORS[exp] for exp in experiments]\n",
    "\n",
    "    # read the data, and obtain the reanalysis data for same time period\n",
    "    ds_list = [xr.open_dataset(fi) for fi in files_to_read]\n",
    "    obs_ds = rean_data.sel(time=ds_list[0].time)\n",
    "\n",
    "    for batch,job_info in regular_jobs.items():\n",
    "        get_product = job_info[\"callback\"]\n",
    "        print(f\"Now working on {model} {init} {batch}\")\n",
    "        for lev in job_info[\"levels\"]:\n",
    "            # Set up output dirs/filenames\n",
    "            outdir = PLOT_DIR / f\"{init}/{batch}/{lev:03d}mb/\"\n",
    "            plot_file = f\"{centre}_{model}_{init}_{batch}_{lev:03d}mb.png\"\n",
    "            outfile = outdir / plot_file\n",
    "            if outfile.exists() and CLOBBER is False:\n",
    "                print(f\"  {outfile} exists; skipping!\")\n",
    "                continue\n",
    "            outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            # Fill in the suptitle\n",
    "            suptitle = job_info[\"suptitle\"].format(lev=lev, hemi=hs, centre=centre, model=model, init=init)\n",
    "\n",
    "            # Subset data using sel and the callback func\n",
    "            da_list = [get_product(ds.sel(plev=lev*100), hemi) for ds in ds_list]\n",
    "            obs_da = get_product(obs_ds.sel(plev=lev*100), hemi)\n",
    "\n",
    "            # Make the plot\n",
    "            fig = make_plume_plots(da_list, obs_da, experiments, suptitle, ylabel=job_info[\"ylabel\"], colors=colors)\n",
    "            fig.savefig(outfile, bbox_inches=\"tight\")\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6903b789-cbc8-49db-8b0e-659f589bfe8f",
   "metadata": {},
   "source": [
    "Now loop over the wavenumber job batch, which requires an additional loop to enumerate the combos of pressure level and wavenumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bb52c-316b-4679-91fb-475cebadf058",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (model, init),group in grouped.items():\n",
    "    centre = CENTRE_TRANSLATOR[model]\n",
    "    hemi = HEMI_TRANSLATOR[init]\n",
    "    hs = \"N\" if hemi == 1 else \"S\"\n",
    "\n",
    "    # sort the group of files in panel order \n",
    "    files_to_read = sorted(list(group), key = lambda fi: PANEL_ORDER_PRECEDENCE[fi.parts[7]]) \n",
    "    experiments = [fi.parts[7] for fi in files_to_read]\n",
    "    colors = [EXPERIMENT_COLORS[exp] for exp in experiments]\n",
    "\n",
    "    # read the data, and obtain the reanalysis data for same time period\n",
    "    ds_list = [xr.open_dataset(fi) for fi in files_to_read]\n",
    "    obs_ds = rean_data.sel(time=ds_list[0].time)\n",
    "\n",
    "    for batch,job_info in wavenum_jobs.items():\n",
    "        get_product = job_info[\"callback\"]\n",
    "        print(f\"Now working on {model} {init} {batch}\")\n",
    "        for lev in job_info[\"levels\"]:\n",
    "            for k in job_info[\"wavenums\"]:\n",
    "                # Set up output dirs/filenames\n",
    "                outdir = PLOT_DIR / f\"{init}/{batch}/{lev:03d}mb/k{k}\"\n",
    "                plot_file = f\"{centre}_{model}_{init}_{batch}{k}_{lev:03d}mb.png\"\n",
    "                outfile = outdir / plot_file\n",
    "                if outfile.exists() and CLOBBER is False:\n",
    "                    print(f\"  {outfile} exists; skipping!\")\n",
    "                    continue\n",
    "                outdir.mkdir(exist_ok=True, parents=True)\n",
    "                \n",
    "                # Fill in the suptitle\n",
    "                suptitle = job_info[\"suptitle\"].format(lev=lev, hemi=hs, k=k, centre=centre, model=model, init=init)\n",
    "    \n",
    "                # Subset data using sel and the callback func\n",
    "                da_list = [get_product(ds.sel(plev=lev*100), hemi, k) for ds in ds_list]\n",
    "                obs_da = get_product(obs_ds.sel(plev=lev*100), hemi, k)\n",
    "    \n",
    "                # Make the plot\n",
    "                fig = make_plume_plots(da_list, obs_da, experiments, suptitle, ylabel=job_info[\"ylabel\"], colors=colors)\n",
    "                fig.savefig(outfile, bbox_inches=\"tight\")\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c444be-32a9-4a7e-8e56-389aa08c2c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
